{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import argparse\n",
    "import time\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = \"V2.0(Editor) 2023-07-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\OneDrive\\Master\\Project\\trans\\scripts\\统计TSS及TES.ipynb 单元格 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/OneDrive/Master/Project/trans/scripts/%E7%BB%9F%E8%AE%A1TSS%E5%8F%8ATES.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 前置参数\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/OneDrive/Master/Project/trans/scripts/%E7%BB%9F%E8%AE%A1TSS%E5%8F%8ATES.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m parser \u001b[39m=\u001b[39m argparse\u001b[39m.\u001b[39mArgumentParser()\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/OneDrive/Master/Project/trans/scripts/%E7%BB%9F%E8%AE%A1TSS%E5%8F%8ATES.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m parser\u001b[39m.\u001b[39madd_argument(\u001b[39m\"\u001b[39m\u001b[39m--annotation_col\u001b[39m\u001b[39m\"\u001b[39m, dest\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mannotation_col\u001b[39m\u001b[39m\"\u001b[39m, required\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m, default\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mgene_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranscript_id\u001b[39m\u001b[39m\"\u001b[39m], nargs\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m, help\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m=[\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgene_id\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtranscript_id\u001b[39m\u001b[39m'\u001b[39m\u001b[39m],\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m要保留的annotation文件的列\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/OneDrive/Master/Project/trans/scripts/%E7%BB%9F%E8%AE%A1TSS%E5%8F%8ATES.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m parser\u001b[39m.\u001b[39madd_argument(\u001b[39m\"\u001b[39m\u001b[39m--quantification_col\u001b[39m\u001b[39m\"\u001b[39m, dest\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mquantification_col\u001b[39m\u001b[39m\"\u001b[39m, required\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m, default\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mannot_gene_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mannot_transcript_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgene_novelty\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranscript_novelty\u001b[39m\u001b[39m\"\u001b[39m], nargs\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m, help\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m要保留的quantification文件的列\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "# 前置参数\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--counts_cutoff\", dest=\"counts_cutoff\", required=False, type=int, default=2, help=\"=2,\\t the cutoff_value of transcript in quantification file\")\n",
    "parser.add_argument(\"--annotation_col\", dest=\"annotation_col\", required=False, type=str, default=[\"gene_id\", \"transcript_id\", \"gene_name\"], nargs=\"*\", help=\"=[\\\"gene_id\\\", \\\"transcript_id\\\", \\\"gene_name\\\"],\\t selected columns of annotation file\")\n",
    "parser.add_argument(\"--quantification_col\", dest=\"quantification_col\", required=False, type=str, default=[\"annot_gene_id\", \"annot_transcript_id\",\"annot_transcript_name\"], nargs=\"*\", help=\"=[\\\"annot_gene_id\\\", \\\"annot_transcript_id\\\",\\\"annot_transcript_name\\\"],\\t selected columns of quantification file\")\n",
    "parser.add_argument(\"--absolute_path\", dest=\"absolute_path\", required=False, action=\"store_true\", default=False, help=\"use absolute path\")\n",
    "parser.add_argument(\"--file_path\", dest=\"file_path\", required=False, type=str, default=\"./\", help=\"the dir of data, if absolute_path is False\")\n",
    "parser.add_argument(\"--input_sample_info\", dest=\"input_sample_info\", required=False, type=str, default=\"0000_sample_info.tsv\", help=\"=0000_sample_info.tsv,\\t the info file of input sample\")\n",
    "parser.add_argument(\"--output_df_filename\", dest=\"output_df_filename\", required=False, type=str, default=\"0001_total_info.tsv\", help=\"=,\\t the output df file of samples\")\n",
    "parser.add_argument(\"--output_pickle_filename\", dest=\"output_pickle_filename\", required=False, type=str, default=\"0001_total_info.pickle\", help=\"=,\\t the output pickle file of samples\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "counts_cutoff = args.counts_cutoff\n",
    "annotation_col = args.annotation_col\n",
    "quantification_col = args.quantification_col\n",
    "absolute_path = args.absolute_path\n",
    "file_path = args.file_path\n",
    "input_sample_info = args.input_sample_info\n",
    "output_df_filename = args.output_df_filename\n",
    "output_pickle_filename = args.output_pickle_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前置参数-debug\n",
    "counts_cutoff = 2\n",
    "\n",
    "annotation_col = [\"gene_id\", \"transcript_id\", \"gene_name\",]\n",
    "quantification_col = [\"annot_gene_id\", \"annot_transcript_id\",\"annot_transcript_name\"]\n",
    "\n",
    "absolute_path = False\n",
    "file_path = \"F:/OneDrive/Master/Project/trans/data/\"\n",
    "input_sample_info = \"0000_sample_info.tsv\"\n",
    "output_df_filename = \"0001_total_info.tsv\"\n",
    "output_pickle_filename = \"0001_total_info.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 补全路径\n",
    "if absolute_path == False:\n",
    "    input_sample_info = \"{}{}\".format(file_path, input_sample_info)\n",
    "    output_df_filename = \"{}{}\".format(file_path, output_df_filename)\n",
    "    output_pickle_filename = \"{}{}\".format(file_path, output_pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 后置参数\n",
    "# 获取样本名\n",
    "sample_info = pandas.read_csv(input_sample_info, sep='\\t')\n",
    "sample_name_list = sample_info[\"GEO_accession\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印参数\n",
    "print('\\n')\n",
    "print(\"[Version]{}\".format(__version__))\n",
    "print(\"[Date]{}\".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "print(\"[Paraments]counts_cutoff: {}\".format(counts_cutoff))\n",
    "print(\"[Paraments]annotation_col: {}\".format(annotation_col))\n",
    "print(\"[Paraments]quantification_col: {}\".format(quantification_col))\n",
    "print(\"[Paraments]input_sample_info: {}\".format(input_sample_info))\n",
    "print(\"[Paraments]sample_name_list: {}\".format(sample_name_list))\n",
    "print(\"[Paraments]output_df_filename: {}\".format(output_df_filename))\n",
    "print(\"[Paraments]output_pickle_filename: {}\".format(output_pickle_filename))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class\n",
    "# 声明一个类，存储所有gene的信息\n",
    "class Total(object):\n",
    "    def __init__(self, sample_list, gene_dict={}):\n",
    "        self.gene_dict = gene_dict  # 存储原始的Gene对象\n",
    "        self.sample_list = sample_list\n",
    "        self.start_dict = {}  # 为了加快check_gene_id()的检索速度测试使用 {<start>: [<gene_id>, <gene_id>],\n",
    "                              #                                          <start>: [<gene_id>, <gene_id>, <gene_id>, ...]}\n",
    "\n",
    "    def __check_gene_id(self, Gene):\n",
    "        # change:\n",
    "        #   检验gene是否已被记录\n",
    "        #       1.gene_id是否已被记录\n",
    "        #       2.在相应染色体及正负链上, 该gene的范围是否已被记录\n",
    "        # output:\n",
    "        #   str, 若该gene_id已被记录则返回'0', 若该gene_id未被记录(start未被记录)则返回'1',\n",
    "        #        若该gene_id未被记录(start已被记录但end未被记录)则返回'2'\n",
    "        #        若该gene_id未被记录(start与end均已被记录)则返回被记录的gene_id\n",
    "        \n",
    "        if Gene.gene_id in self.gene_dict.keys():\n",
    "            return '0'\n",
    "        else:\n",
    "            if Gene.start not in self.start_dict.keys():\n",
    "                return '1'\n",
    "            else:\n",
    "                gene_id_list = self.start_dict.get(Gene.start)\n",
    "                for existed_gene in gene_id_list:\n",
    "                    existed_gene = self.gene_dict.get(existed_gene)\n",
    "                    if existed_gene.strand != Gene.strand:\n",
    "                        continue\n",
    "                    elif existed_gene.chr != Gene.chr:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if existed_gene.end == Gene.end:\n",
    "                            return existed_gene.gene_id\n",
    "                return '2'\n",
    "\n",
    "\n",
    "    def add_gene(self, Gene):\n",
    "        # change:\n",
    "        #   若gene信息未被记录, 则向gene_dict添加Gene对象，并向start_dict添加相关信息\n",
    "        # output:\n",
    "        #   str, 若成功添加该gene信息则返回\"True\"，若该gene_id已被记录则返回\"False\",\n",
    "        #        若该gene_id未被记录但相关信息已被记录则返回相应的gene_id\n",
    "\n",
    "        check_exist = self.__check_gene_id(Gene)\n",
    "        if check_exist == '0':\n",
    "            return \"False\"\n",
    "        elif check_exist == '1':\n",
    "            self.gene_dict[Gene.gene_id] = Gene\n",
    "            self.start_dict[Gene.start] = [Gene.gene_id]\n",
    "            return \"True\"\n",
    "        elif check_exist == '2':\n",
    "            self.gene_dict[Gene.gene_id] = Gene\n",
    "            temp = self.start_dict.get(Gene.start)\n",
    "            temp.append(Gene.gene_id)\n",
    "            self.start_dict[Gene.start] = temp\n",
    "            return \"True\"\n",
    "        else:\n",
    "            return check_exist\n",
    "    \n",
    "\n",
    "    def get_df(self, sample_name_list=[]):\n",
    "        # change:\n",
    "        #   整理该对象下所有gene的信息到一个df中\n",
    "        # output:\n",
    "        #   df, pandas.DataFrame, 含有列chr, strand, source, gene_id, transcript_id, transcript_start, transcript_end, sample_name...\n",
    "        sample_name_list = sample_name_list\n",
    "\n",
    "        gene_id_list = list(self.gene_dict.keys())\n",
    "        columns = [\"chr\", \"strand\", \"source\", \"gene_id\", \"gene_name\",\n",
    "                   \"transcript_id\", \"transcript_name\", \"transcript_start\", \"transcript_end\"]\n",
    "        columns = columns + sample_name_list\n",
    "        df = pandas.DataFrame(columns=columns)\n",
    "        \n",
    "        \"\"\"progress_num = 0  # 进度条\n",
    "        progress_end = len(gene_id_list)  # 进度条\n",
    "        for gene_id in gene_id_list:\n",
    "            progress_num +=1  # 进度条\n",
    "            print(\"{}/{}\".format(progress_num,progress_end), end='\\r')  # 打印进度条\n",
    "\n",
    "            temp_df = self.gene_dict[gene_id].get_df(sample_name_list)\n",
    "            df = pandas.concat([df, temp_df], axis=0)\"\"\"\n",
    "        \n",
    "        # 为了加快concat速度\n",
    "        remain_num = len(gene_id_list)  # 进度条\n",
    "        while remain_num != 0:\n",
    "            print(\"{}\".format(remain_num), end='\\r')  # 打印进度条\n",
    "\n",
    "            if remain_num >= 30:\n",
    "                temp1 = gene_id_list.pop()\n",
    "                temp2 = gene_id_list.pop()\n",
    "                temp3 = gene_id_list.pop()\n",
    "                temp4 = gene_id_list.pop()\n",
    "                temp5 = gene_id_list.pop()\n",
    "                temp6 = gene_id_list.pop()\n",
    "                temp7 = gene_id_list.pop()\n",
    "                temp8 = gene_id_list.pop()\n",
    "                temp9 = gene_id_list.pop()\n",
    "                temp10 = gene_id_list.pop()\n",
    "                temp11 = gene_id_list.pop()\n",
    "                temp12 = gene_id_list.pop()\n",
    "                temp13 = gene_id_list.pop()\n",
    "                temp14 = gene_id_list.pop()\n",
    "                temp15 = gene_id_list.pop()\n",
    "                temp16 = gene_id_list.pop()\n",
    "                temp17 = gene_id_list.pop()\n",
    "                temp18 = gene_id_list.pop()\n",
    "                temp19 = gene_id_list.pop()\n",
    "                temp20 = gene_id_list.pop()\n",
    "                temp21 = gene_id_list.pop()\n",
    "                temp22 = gene_id_list.pop()\n",
    "                temp23 = gene_id_list.pop()\n",
    "                temp24 = gene_id_list.pop()\n",
    "                temp25 = gene_id_list.pop()\n",
    "                temp26 = gene_id_list.pop()\n",
    "                temp27 = gene_id_list.pop()\n",
    "                temp28 = gene_id_list.pop()\n",
    "                temp29 = gene_id_list.pop()\n",
    "                temp30 = gene_id_list.pop()\n",
    "\n",
    "                temp1 = self.gene_dict[temp1].get_df(sample_name_list)\n",
    "                temp2 = self.gene_dict[temp2].get_df(sample_name_list)\n",
    "                temp3 = self.gene_dict[temp3].get_df(sample_name_list)\n",
    "                temp4 = self.gene_dict[temp4].get_df(sample_name_list)\n",
    "                temp5 = self.gene_dict[temp5].get_df(sample_name_list)\n",
    "                temp6 = self.gene_dict[temp6].get_df(sample_name_list)\n",
    "                temp7 = self.gene_dict[temp7].get_df(sample_name_list)\n",
    "                temp8 = self.gene_dict[temp8].get_df(sample_name_list)\n",
    "                temp9 = self.gene_dict[temp9].get_df(sample_name_list)\n",
    "                temp10 = self.gene_dict[temp10].get_df(sample_name_list)\n",
    "                temp11 = self.gene_dict[temp11].get_df(sample_name_list)\n",
    "                temp12 = self.gene_dict[temp12].get_df(sample_name_list)\n",
    "                temp13 = self.gene_dict[temp13].get_df(sample_name_list)\n",
    "                temp14 = self.gene_dict[temp14].get_df(sample_name_list)\n",
    "                temp15 = self.gene_dict[temp15].get_df(sample_name_list)\n",
    "                temp16 = self.gene_dict[temp16].get_df(sample_name_list)\n",
    "                temp17 = self.gene_dict[temp17].get_df(sample_name_list)\n",
    "                temp18 = self.gene_dict[temp18].get_df(sample_name_list)\n",
    "                temp19 = self.gene_dict[temp19].get_df(sample_name_list)\n",
    "                temp20 = self.gene_dict[temp20].get_df(sample_name_list)\n",
    "                temp21 = self.gene_dict[temp21].get_df(sample_name_list)\n",
    "                temp22 = self.gene_dict[temp22].get_df(sample_name_list)\n",
    "                temp23 = self.gene_dict[temp23].get_df(sample_name_list)\n",
    "                temp24 = self.gene_dict[temp24].get_df(sample_name_list)\n",
    "                temp25 = self.gene_dict[temp25].get_df(sample_name_list)\n",
    "                temp26 = self.gene_dict[temp26].get_df(sample_name_list)\n",
    "                temp27 = self.gene_dict[temp27].get_df(sample_name_list)\n",
    "                temp28 = self.gene_dict[temp28].get_df(sample_name_list)\n",
    "                temp29 = self.gene_dict[temp29].get_df(sample_name_list)\n",
    "                temp30 = self.gene_dict[temp30].get_df(sample_name_list)\n",
    "                df = pandas.concat([df, temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8, temp9, temp10,\n",
    "                                    temp11, temp12, temp13, temp14, temp15, temp16, temp17, temp18, temp19, temp20,\n",
    "                                    temp21, temp22, temp23, temp24, temp25, temp26, temp27, temp28, temp29, temp30],\n",
    "                                    axis=0)\n",
    "            else:\n",
    "                temp1 = gene_id_list.pop()\n",
    "                temp1 = self.gene_dict[temp1].get_df(sample_name_list)\n",
    "                df = pandas.concat([df, temp1], axis=0)\n",
    "\n",
    "            remain_num = len(gene_id_list)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "# 定义一个类，以存储基因的相关信息\n",
    "#   具有属性：染色体号，source，正负链，start/end，包含的转录本id\n",
    "#   存储：转录本名称及范围、外显子范围\n",
    "#   具有方法：\n",
    "#       1.添加外显子\n",
    "#       2.添加转录本\n",
    "#       3.统计该基因的转录本数量\n",
    "\n",
    "# 需要建立一个df, 可以实现gene_id与transcript_id的互查\n",
    "\n",
    "# 类\n",
    "class Gene(object):\n",
    "    def __init__(self, chr, gene_id, gene_name, source, \n",
    "                 strand, start, end, \n",
    "                 transcript_dict, exon_dict):\n",
    "        self.chr = chr  # str\n",
    "        self.gene_id = gene_id  # str\n",
    "        self.gene_name = gene_name\n",
    "        self.source = source  # str\n",
    "        self.strand = strand  # str\n",
    "        self.start = int(start)  # int\n",
    "        self.end = int(end)  # int\n",
    "        # 可删除 self.counts_dict = counts_dict  # {sample_name1: counts, sample_name2: counts, ...}\n",
    "        self.transcript_dict = transcript_dict  # {transcript_id: {\"transcript_name\": <transcript_name>\n",
    "                                                #                  \"range\": [<start>, <end>],\n",
    "                                                #                  \"exon_range\": {<start>: [<end>], <start>: [<end>, <end>], ...},\n",
    "                                                #                  <sample_name1>: <counts>,\n",
    "                                                #                  <sample_name2>: <counts>, ...}\n",
    "                                                # }\n",
    "        self.exon_dict = exon_dict  # {start: [end], start: [end, end, ...], ...}\n",
    "\n",
    "\n",
    "    def __check_exon_exist(self, exon_start, exon_end):\n",
    "        # change:\n",
    "        #   检查指定的exon是否已被记录\n",
    "        # output:\n",
    "        #   int, 若start未被记录则返回0, 若start被记录end未被记录则返回1, 若该exon的start与end均已被记录则返回2\n",
    "        \n",
    "        if exon_start not in self.exon_dict.keys():\n",
    "            return 0\n",
    "        else:\n",
    "            if exon_end not in self.exon_dict.get(exon_start):\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "\n",
    "\n",
    "    def add_exon(self, exon_start, exon_end):\n",
    "        # change:\n",
    "        #   对基因增加一个exon\n",
    "        # output:\n",
    "        #   str, 若成功添加exon则返回\"success_add\", 若该exon已被记录则返回\"existed_exon\"\n",
    "\n",
    "        exon_exist_mark = self.__check_exon_exist(exon_start, exon_end)\n",
    "        if exon_exist_mark == 0:\n",
    "            # 存储start与end未记录的exon的信息\n",
    "            self.exon_dict[exon_start] = [exon_end]\n",
    "            return \"success add\"\n",
    "        elif exon_exist_mark == 1:\n",
    "            # 存储start已记录而end未记录的exon的信息\n",
    "            self.exon_dict[exon_start].append(exon_end)\n",
    "            return \"success add\"\n",
    "        else:\n",
    "            return \"existed_exon\"\n",
    "\n",
    "\n",
    "    def __check_transcript_exist(self, transcript_id, start, end, exon_list):\n",
    "        # change:\n",
    "        #   检验指定的transcript是否已被记录\n",
    "        # output:\n",
    "        #   str, 若trnascript_id已被记录则返回transcript_id, 表示该transcript已被记录, 若transcript_id未被记录则检验该transcript的range是否已被记录\n",
    "        #           若该transcript的range未被记录，则返回1，表示该transcript未被记录\n",
    "        #           若该transcript的range已被记录, 则进一步检验该transcript的exon组成是否已被记录\n",
    "        #               若该transcript的exon组成已被记录, 则返回exist_transcript_id, 表示该transcript已被记录\n",
    "        #               若该transcript的exon组成未被记录，则返回3, 表示该transcript未被记录\n",
    "\n",
    "        if transcript_id in self.transcript_dict.keys():\n",
    "            return transcript_id  # transcript_id已被记录\n",
    "        else:\n",
    "            for exist_transcript_id in self.transcript_dict.keys():\n",
    "                if start != self.transcript_dict[exist_transcript_id][\"range\"][0]:\n",
    "                    continue\n",
    "                else:\n",
    "                    if end != self.transcript_dict[exist_transcript_id][\"range\"][1]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # transcript的id未被记录, 但start与end均已被记录且与exist_transcript_id的start与end一致\n",
    "                        # 接下来比较transcript与exist_transcript的exon组成是否一致\n",
    "\n",
    "                        # 将exist_transcript的exon_range由dict转为list\n",
    "                        exist_transcript_exon = []\n",
    "                        for exist_start,exist_end_list in self.transcript_dict[exist_transcript_id][\"exon_range\"].items():\n",
    "                            for exist_end in exist_end_list:\n",
    "                                exist_transcript_exon.append([exist_start, exist_end])\n",
    "\n",
    "                        # 判断exon的数量是否一致,\n",
    "                        length = len(exon_list)\n",
    "                        if length != len(exist_transcript_exon):\n",
    "                            # 若不一致则表示该transcript未被记录\n",
    "                            return '3'  # range一致但exon组成不一致, 新transcript\n",
    "                        else:\n",
    "                            # 若一致，判断exon组成是否一致\n",
    "                            # 将两个exon_list按start的位置升序排序，在两两比较list是否一致\n",
    "                            exon_list = sorted(exon_list, key=lambda x: x[0])\n",
    "                            exist_transcript_exon = sorted(exist_transcript_exon, key=lambda x: x[0])\n",
    "                            for i in range(0,length):\n",
    "                                if exon_list[i] != exist_transcript_exon[i]:\n",
    "                                    # 若存在不一致，则表示transcript为新transcript\n",
    "                                    return '3'  # range一致但exon组成不一致, 新transcript\n",
    "                            return exist_transcript_id  # range一致且exon一致, 旧transcript\n",
    "            return '1'  # range未被记录, 新transcript\n",
    "\n",
    "\n",
    "    def add_transcript(self, transcript_id, transcript_name, start, end, exon_list, sample_name, sample_counts):\n",
    "        # change:\n",
    "        #   对基因增加一个新的transcript, 并记录该transcript在相应样本中的counts数\n",
    "        # output:\n",
    "        #   bool, 若成功添加该transcript并添加了相应counts数则返回True，若未添加transcript只添加了相应counts数则返回False\n",
    "\n",
    "        exist_mark = self.__check_transcript_exist(transcript_id, start, end, exon_list)\n",
    "        if exist_mark == '1' or exist_mark == '3':\n",
    "            # 将exon_list转换为transcript_dict中exon_range的格式  {<start>: [<end>], <start>: [<end>, <end>], ...}\n",
    "            exon_range = {}\n",
    "            for [exon_start, exon_end] in exon_list:\n",
    "                if exon_start not in exon_range.keys():\n",
    "                    exon_range[exon_start] = [exon_end]  # list type\n",
    "                else:\n",
    "                    temp = exon_range[exon_start]\n",
    "                    temp.append(exon_end)\n",
    "                    exon_range[exon_start] = temp\n",
    "            # gene中的transcript_dict新增一个transcript_id，并添加相应的键值对\n",
    "            self.transcript_dict[transcript_id] = {\"transcript_name\": transcript_name,\n",
    "                                                   \"range\": [start, end],\n",
    "                                                   \"exon_range\": exon_range,\n",
    "                                                   sample_name: sample_counts\n",
    "                                                   }\n",
    "            return True\n",
    "        else:\n",
    "            # 仅更新exist_transcript_id在相应样本中的counts数\n",
    "            self.transcript_dict[exist_mark][sample_name] = sample_counts\n",
    "            return False\n",
    "\n",
    "\n",
    "    def get_df(self, sample_name_list=[]):\n",
    "        # change:\n",
    "        #   整理该gene中的所有信息，返回一个pandas.DataFrame对象\n",
    "        # output:\n",
    "        #   df, pandas.DataFrame, 含有列chr, strand, source, gene_id, transcript_id, transcript_start, transcript_end, sample_name...\n",
    "        sample_name_list = sample_name_list\n",
    "\n",
    "        chr = self.chr\n",
    "        strand = self.strand\n",
    "        source = self.source\n",
    "        gene_id = self.gene_id\n",
    "        gene_name = self.gene_name\n",
    "\n",
    "        columns = [\"chr\", \"strand\", \"source\", \"gene_id\", \"gene_name\", \n",
    "                   \"transcript_id\", \"transcript_name\", \"transcript_start\", \"transcript_end\"]\n",
    "        columns = columns + sample_name_list\n",
    "        df = pandas.DataFrame(index=list(self.transcript_dict.keys()),\n",
    "                              columns=columns)\n",
    "        \n",
    "        for transcript_id in self.transcript_dict.keys():\n",
    "            transcript_name = self.transcript_dict[transcript_id][\"transcript_name\"]\n",
    "            transcript_start = self.transcript_dict[transcript_id][\"range\"][0]\n",
    "            transcript_end = self.transcript_dict[transcript_id][\"range\"][1]\n",
    "\n",
    "            df.at[transcript_id, \"chr\"] = chr\n",
    "            df.at[transcript_id, \"strand\"] = strand\n",
    "            df.at[transcript_id, \"source\"] = source\n",
    "            df.at[transcript_id, \"gene_id\"] = gene_id\n",
    "            df.at[transcript_id, \"gene_name\"] = gene_name\n",
    "            df.at[transcript_id, \"transcript_id\"] = transcript_id\n",
    "            df.at[transcript_id, \"transcript_name\"] = transcript_name\n",
    "            df.at[transcript_id, \"transcript_start\"] = transcript_start\n",
    "            df.at[transcript_id, \"transcript_end\"] = transcript_end\n",
    "\n",
    "            for sample_name in sample_name_list:\n",
    "                df.at[transcript_id, sample_name] = self.transcript_dict[transcript_id].get(sample_name, 0)\n",
    "        \n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "def log(function):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print('\\n')\n",
    "        print(\"[Function]{} start.\".format(function.__name__))\n",
    "        print(\"\\t[Time]time: {}\".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        for key, value in kwargs.items():\n",
    "            if type(value) in [int, str, bool, list]:\n",
    "                print(\"\\t[Paraments]{}: {}\".format(key, value))\n",
    "            else:\n",
    "                print('\\t[Paraments]{}: <...>'.format(key, value))\n",
    "        result = function(*args, **kwargs)\n",
    "        print(\"[{}]{} finished.\".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time())),\n",
    "                                        function.__name__))\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def get_file_path(file_path, sample_name_list):\n",
    "    # input:\n",
    "    #   file_path, str, data文件夹路径\n",
    "    #   sample_name_list, list, 含有样本名的列表\n",
    "    # change:\n",
    "    #   搜索file_path下的每个样本文件夹中的文件名,\n",
    "    #       记录annotation及quantification文件的绝对路径\n",
    "    # output:\n",
    "    #   sample_file_location, dict, 该字典存储每个样本的annotation及quantification文件的绝对路径\n",
    "    #                               {<sample1>:{\"annotation\": <dir1>, \"quantification\": <dir2>},\n",
    "    #                                <sample2>:{\"annotation\": <dir1>, \"quantification\": <dir2>}, ...}\n",
    "\n",
    "    file_path = file_path\n",
    "    sample_name_list = sample_name_list\n",
    "\n",
    "    sample_file_location = {sample: {} for sample in sample_name_list}\n",
    "    for sample in sample_name_list:\n",
    "        filename_list = os.listdir(\"{}raw_data/{}\".format(file_path, sample))\n",
    "        for filename in filename_list:\n",
    "            if re.search(pattern=\"annotation\", string=filename) is not None:\n",
    "                sample_file_location[sample][\"annotation\"] = \"{}raw_data/{}/{}\".format(file_path, sample, filename)\n",
    "            elif re.search(pattern=\"quantification\", string=filename) is not None:\n",
    "                sample_file_location[sample][\"quantification\"] = \"{}raw_data/{}/{}\".format(file_path, sample, filename)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return sample_file_location\n",
    "\n",
    "\n",
    "def load_annotation(input_filename, additional_info, only_type=\"transcript\"):\n",
    "    input_filename = input_filename\n",
    "    additional_info_list = additional_info\n",
    "    only_type = only_type\n",
    "\n",
    "    columns_name = [\"chr\", \"source\", \"type\", \"start\", \"end\", \"strand\"]\n",
    "    columns_name = columns_name + additional_info_list\n",
    "\n",
    "    df = []\n",
    "    with open(input_filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.split('\\t')\n",
    "\n",
    "            # 只保留transcript\n",
    "            if only_type == \"all\":\n",
    "                pass\n",
    "            elif line[2] != only_type:\n",
    "                continue\n",
    "            \n",
    "            # 过滤掉 chr为ERCC 或 未能准确匹配到染色体上 的注释\n",
    "            if line[0][0:4] == \"ERCC\":\n",
    "                continue\n",
    "            elif line[0][0:5] == \"chrUn\":\n",
    "                continue\n",
    "            elif line[0][-6:] == \"random\":\n",
    "                continue\n",
    "            \n",
    "            # 去除不想要的列\n",
    "            line.pop(7)\n",
    "            line.pop(5)\n",
    "\n",
    "            # 统计最后一列的信息\n",
    "            additional_info = {}\n",
    "            temp_line = line[-1].split(';')\n",
    "            temp_line.remove('')\n",
    "            temp_line = [i.strip(' ') for i in temp_line]\n",
    "            for i in temp_line:\n",
    "                key,value = i.split(' ')\n",
    "                value = value.strip('\"')\n",
    "                additional_info[key] = value\n",
    "\n",
    "            # 保存前8列以及指定信息\n",
    "            line = line[0:6]\n",
    "            for i in additional_info_list:\n",
    "                line.append(additional_info.get(i,\"\"))\n",
    "\n",
    "            df.append(line)\n",
    "\n",
    "    df = pandas.DataFrame(df, columns=columns_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_quantification(input_filename,\n",
    "                        sample_name,\n",
    "                        cutoff_value=1,\n",
    "                        col=[\"annot_gene_id\", \"annot_transcript_id\", \"gene_novelty\", \"transcript_novelty\"]):\n",
    "    # input:\n",
    "    #   input_filename, str, the absolute path of quantification file\n",
    "    #   sample_name, str, the name of sample\n",
    "    #   col, list, the columns need to be retained of the df\n",
    "    # change:\n",
    "    #   load input file and retain the specified columns\n",
    "    #   filter rows according to cutoff_value\n",
    "    # output:\n",
    "    input_filename = input_filename\n",
    "    sample_name = sample_name\n",
    "    cutoff_value = cutoff_value\n",
    "    col = col\n",
    "    \n",
    "    df = pandas.read_csv(input_filename, sep='\\t')\n",
    "    col_list = df.columns.to_list()\n",
    "    df.rename(columns={col_list[-1]: sample_name}, inplace=True)\n",
    "    col = [col_list.index(x) for x in col]\n",
    "    col.append(len(col_list)-1)  # the last column in df\n",
    "    df = df.iloc[:,col]\n",
    "\n",
    "    sig_row = df[sample_name].map(lambda x: x >= cutoff_value)\n",
    "    df = df.loc[sig_row,:]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_quantification_annotation(quantification, annotation):\n",
    "    df_quan = quantification\n",
    "    df_annotation = annotation\n",
    "\n",
    "    # 注意：这一步删除了annotation中不存在于quantification的transcript\n",
    "    df = pandas.merge(df_quan, df_annotation,\n",
    "                    left_on=\"annot_transcript_id\", right_on=\"transcript_id\",\n",
    "                    how=\"left\")\n",
    "    # 删除quantification中不存在于annotation的transcript\n",
    "    df = df.dropna(axis=0, how=\"any\", subset=\"transcript_id\")\n",
    "    # 删除df中的gene_id列与transcript_id列，因为与quantification重复\n",
    "    df = df.drop(labels=[\"gene_id\", \"transcript_id\"], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_gene_info(df):\n",
    "    # 统计每个基因的TSS及TES的数量\n",
    "    df = df\n",
    "\n",
    "    df_group = df.groupby(\"annot_gene_id\")\n",
    "    gene_info = pandas.DataFrame(index=list(set(df[\"annot_gene_id\"].to_list())),\n",
    "                                columns=[\"start\",\"end\",\"strand\",\"transcripts\"])\n",
    "\n",
    "    process_n = 0\n",
    "    process_end = len(df_group)\n",
    "    for gene_id in df_group.groups.keys():\n",
    "        # 进度条\n",
    "        process_n += 1\n",
    "        print(\"\\t[Process]{}/{}\".format(process_n, process_end), end='\\r')\n",
    "        # 获得单个基因的所有转录本信息\n",
    "        temp_df = df_group.get_group(gene_id)\n",
    "\n",
    "        num_transcript = temp_df.shape[0]\n",
    "        strand = list(set(temp_df[\"strand\"].to_list()))\n",
    "        # 根据strad对起始点及终止点的数量进行统计\n",
    "        if len(strand) == 1 and strand[0] == '-':\n",
    "            # 负链\n",
    "            num_end = len(set(temp_df[\"start\"].to_list()))\n",
    "            num_start = len(set(temp_df[\"end\"].to_list()))\n",
    "            strand = strand[0]\n",
    "        elif len(strand) == 1 and strand[0] == '+':\n",
    "            # 正链\n",
    "            num_start = len(set(temp_df[\"start\"].to_list()))\n",
    "            num_end = len(set(temp_df[\"end\"].to_list()))\n",
    "            strand = strand[0]\n",
    "        else:\n",
    "            raise KeyError(\"[错误]strand: {}\".format(strand))\n",
    "\n",
    "        gene_info.at[gene_id, \"start\"] = num_start\n",
    "        gene_info.at[gene_id, \"end\"] = num_end\n",
    "        gene_info.at[gene_id, \"strand\"] = strand\n",
    "        gene_info.at[gene_id, \"transcripts\"] = num_transcript\n",
    "    \n",
    "    return gene_info\n",
    "\n",
    "@log\n",
    "def load_sample(total, annotation_location, quantification_location, sample_name, \n",
    "                counts_cutoff, annotation_col, quantification_col):\n",
    "    # input:\n",
    "    #   total, Total, 含有整理的所有信息的对象\n",
    "    #   annotation_location, str, 单个样本的annotation文件\n",
    "    #   quantification_location, str, 单个样本的quantification文件\n",
    "    #   sample_name, str, 单个样本的样本名称\n",
    "    #   counts_cutoff, int, quantification文件中counts的阈值(>=value)\n",
    "    #   annotation_col, list, 在annotation文件中要保留的额外的列名\n",
    "    #   quantification_col, list, 在quantification文件中要保留的额外的列名\n",
    "    # change:\n",
    "    #   整合单个样本的annotation和quantification数据到total对象中\n",
    "    # output:\n",
    "    #   total, Total, 存储整合annotation和quantification文件得到的所有数据\n",
    "\n",
    "    total = total\n",
    "    annotation_location = annotation_location\n",
    "    quantification_location = quantification_location\n",
    "    sample_name = sample_name\n",
    "    counts_cutoff = counts_cutoff\n",
    "    annotation_col = annotation_col\n",
    "    quantification_col = quantification_col\n",
    "\n",
    "    # 获取单个样本的transcript信息\n",
    "    df_annotation = load_annotation(input_filename=annotation_location,\n",
    "                            additional_info=annotation_col,\n",
    "                            only_type=\"transcript\")\n",
    "    df_quantification = load_quantification(input_filename=quantification_location,\n",
    "                                            sample_name=sample_name,\n",
    "                                            cutoff_value=counts_cutoff,\n",
    "                                            col=quantification_col)\n",
    "    df_temp = merge_quantification_annotation(df_quantification, df_annotation)\n",
    "    df_temp[sample_name] = df_temp[sample_name].astype(int)\n",
    "    df_temp[\"start\"] = df_temp[\"start\"].astype(int)\n",
    "    df_temp[\"end\"] = df_temp[\"end\"].astype(int)\n",
    "\n",
    "\n",
    "    # 获取单个样本的gene信息\n",
    "    gene_info = load_annotation(input_filename=annotation_location,\n",
    "                            additional_info=annotation_col,\n",
    "                            only_type=\"gene\")\n",
    "    expressed_gene = list(set(df_temp[\"annot_gene_id\"].to_list()))\n",
    "    expressed_gene = pandas.DataFrame(expressed_gene)\n",
    "    gene_info = pandas.merge(expressed_gene, gene_info, left_on=0, right_on=\"gene_id\", how=\"left\")\n",
    "    gene_info[\"start\"] = gene_info[\"start\"].astype(int)\n",
    "    gene_info[\"end\"] = gene_info[\"end\"].astype(int)\n",
    "\n",
    "    # 记录单个样本的gene信息\n",
    "    exist_gene_id = {}  # 存储重复出现的gene的id {<new_gene_id>: existed_gene_id}\n",
    "    for i in gene_info.index:\n",
    "        chr = gene_info.at[i, \"chr\"]\n",
    "        gene_id = gene_info.at[i, \"gene_id\"]\n",
    "        gene_name = gene_info.at[i, \"gene_name\"]\n",
    "        source = gene_info.at[i, \"source\"]\n",
    "        strand = gene_info.at[i, \"strand\"]\n",
    "        start = gene_info.at[i, \"start\"]\n",
    "        end = gene_info.at[i, \"end\"]\n",
    "        \n",
    "        # gene_mark有三种值: \"True\", \"False\", <gene_id> 此处的<gene_id>代表与当前Gene对象重复的gene的id\n",
    "        gene_mark = total.add_gene(Gene(chr=chr, gene_id=gene_id, gene_name=gene_name, source=source,\n",
    "                                   strand=strand, start=start, end=end,\n",
    "                                   transcript_dict={}, exon_dict={}))\n",
    "        if gene_mark == \"True\" or gene_mark == \"False\":\n",
    "            pass\n",
    "        else:\n",
    "            exist_gene_id[gene_id] = gene_mark\n",
    "\n",
    "\n",
    "    # 获取单个样本的exon信息\n",
    "    exon_info = load_annotation(input_filename=annotation_location,\n",
    "                                additional_info=annotation_col,\n",
    "                                only_type=\"exon\")\n",
    "    expressed_gene = list(set(df_temp[\"annot_transcript_id\"].to_list()))\n",
    "    expressed_gene = pandas.DataFrame(expressed_gene)\n",
    "    exon_info = pandas.merge(expressed_gene, exon_info, left_on=0, right_on=\"transcript_id\")\n",
    "    exon_info[\"start\"] = exon_info[\"start\"].astype(int)\n",
    "    exon_info[\"end\"] = exon_info[\"end\"].astype(int)\n",
    "\n",
    "    # 记录单个样本的exon信息\n",
    "    exon_info_group = exon_info.groupby(\"transcript_id\")\n",
    "    for transcript_id in exon_info_group.groups.keys():\n",
    "        temp_df = exon_info_group.get_group(transcript_id)\n",
    "\n",
    "        gene_id = temp_df.at[temp_df.index[0], \"gene_id\"]\n",
    "        # 由于单个样本的gene信息已在先前步骤中被统计，所以，此时再对同一样本的gene添加exon信息时,\n",
    "            # 不会出现未被记录的gene. 也就是说，此处exon所对应的gene可分为两种情况：\n",
    "            #   1.该gene_id已被记录  2.该gene_id未被记录但已记录相应的gene信息(即gene信息相同但id不同)\n",
    "        if gene_id in exist_gene_id.keys():\n",
    "            # 该exon所在的gene属于重复出现的gene(该gene_id被映射到其他的gene_id)\n",
    "            gene_id = exist_gene_id.get(gene_id)\n",
    "        else:\n",
    "            # 该exon所在的gene未被映射到其他gene_id\n",
    "            pass\n",
    "        \n",
    "        # 向指定gene_id添加exon信息\n",
    "        for i in temp_df.index:\n",
    "            total.gene_dict[gene_id].add_exon(temp_df.at[i,\"start\"], temp_df.at[i,\"end\"])\n",
    "\n",
    "\n",
    "    # 记录单个样本的transcript信息\n",
    "    # 根据df_temp\n",
    "    # 向每一个gene添加相关的transcript_id, transcript的start及end, 在单个样本中的counts数量\n",
    "    temp_transcript_info = df_temp.set_index(\"annot_transcript_id\")\n",
    "    exon_info_group = exon_info.groupby(\"transcript_id\")\n",
    "    for transcript_id in temp_transcript_info.index:\n",
    "        temp_exon_info = exon_info_group.get_group(transcript_id)\n",
    "\n",
    "        transcript_name = temp_transcript_info.at[transcript_id, \"annot_transcript_name\"]\n",
    "        start = temp_transcript_info.at[transcript_id, \"start\"]\n",
    "        end = temp_transcript_info.at[transcript_id, \"end\"]\n",
    "        sample_name = sample_name\n",
    "        sample_counts = temp_transcript_info.at[transcript_id, sample_name]\n",
    "        exon_list = [[temp_exon_info.at[i, \"start\"], temp_exon_info.at[i, \"end\"]] for i in temp_exon_info.index]\n",
    "        \n",
    "        gene_id = temp_transcript_info.at[transcript_id, \"annot_gene_id\"]\n",
    "        if gene_id in exist_gene_id.keys():\n",
    "            gene_id = exist_gene_id.get(gene_id)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        total.gene_dict[gene_id].add_transcript(transcript_id=transcript_id,\n",
    "                                                transcript_name=transcript_name,\n",
    "                                                start=start, end=end,\n",
    "                                                exon_list=exon_list,\n",
    "                                                sample_name=sample_name,\n",
    "                                                sample_counts=sample_counts)\n",
    "\n",
    "\n",
    "    # 获取单个样本的sample_name并添加到total的对象中\n",
    "    sample_name = sample_name\n",
    "    sample_list = total.sample_list\n",
    "    sample_list.append(sample_name)\n",
    "    total.sample_list = sample_list\n",
    "\n",
    "    return total\n",
    "\n",
    "@log\n",
    "def save_df(total, file_path):\n",
    "    # input:\n",
    "    #   total, Total, 存储数据的对象\n",
    "    #   file_path, str, 要保存的文件的绝对路径\n",
    "    # change:\n",
    "    #   将Total对象转为pandas.DataFrame并保存到指定位置\n",
    "    # output:\n",
    "    #   df, pandas.DataFrame, 由Total转换而来的df\n",
    "    total = total\n",
    "    file_path = file_path\n",
    "\n",
    "    df = total.get_df(total.sample_list)\n",
    "    df = df.sort_values(by=\"gene_id\")\n",
    "    df = df.sort_values(by=\"chr\")\n",
    "    df.to_csv(file_path, sep='\\t')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备input文件的绝对路径\n",
    "file_path = get_file_path(file_path=file_path,\n",
    "                          sample_name_list=sample_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备存储gene信息\n",
    "total = Total(sample_list=[], gene_dict={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Function]load_sample start.\n",
      "\t[Time]time: 2023-07-12 09:38:45\n",
      "\t[Paraments]annotation_location: F:/OneDrive/Master/Project/trans/data/raw_data/GSM6783527/GSM6783527_ENCFF384PHN_transcriptome_annotations_GRCh38.gtf\n",
      "\t[Paraments]quantification_location: F:/OneDrive/Master/Project/trans/data/raw_data/GSM6783527/GSM6783527_ENCFF816TJN_transcript_quantifications_GRCh38.tsv\n",
      "\t[Paraments]sample_name: GSM6783527\n",
      "\t[Paraments]counts_cutoff: 2\n",
      "\t[Paraments]annotation_col: ['gene_id', 'transcript_id', 'gene_name']\n",
      "\t[Paraments]quantification_col: ['annot_gene_id', 'annot_transcript_id', 'annot_transcript_name']\n",
      "[2023-07-12 09:39:52]load_sample finished.\n",
      "\n",
      "\n",
      "[Function]load_sample start.\n",
      "\t[Time]time: 2023-07-12 09:39:52\n",
      "\t[Paraments]annotation_location: F:/OneDrive/Master/Project/trans/data/raw_data/GSM6782551/GSM6782551_ENCFF856FNN_transcriptome_annotations_GRCh38.gtf\n",
      "\t[Paraments]quantification_location: F:/OneDrive/Master/Project/trans/data/raw_data/GSM6782551/GSM6782551_ENCFF217QQW_transcript_quantifications_GRCh38.tsv\n",
      "\t[Paraments]sample_name: GSM6782551\n",
      "\t[Paraments]counts_cutoff: 2\n",
      "\t[Paraments]annotation_col: ['gene_id', 'transcript_id', 'gene_name']\n",
      "\t[Paraments]quantification_col: ['annot_gene_id', 'annot_transcript_id', 'annot_transcript_name']\n",
      "[2023-07-12 09:41:10]load_sample finished.\n"
     ]
    }
   ],
   "source": [
    "# 读取每个样本的数据\n",
    "for sample_name in sample_name_list:\n",
    "    quantification_file_location = file_path[sample_name][\"quantification\"]\n",
    "    annotation_file_location = file_path[sample_name][\"annotation\"]\n",
    "\n",
    "    total = load_sample(total,\n",
    "                        annotation_location=annotation_file_location,\n",
    "                        quantification_location=quantification_file_location,\n",
    "                        sample_name=sample_name,\n",
    "                        counts_cutoff=counts_cutoff,\n",
    "                        annotation_col=annotation_col,\n",
    "                        quantification_col=quantification_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Function]save_df start.\n",
      "\t[Time]time: 2023-07-12 09:41:26\n",
      "[2023-07-12 09:42:37]save_df finished.\n"
     ]
    }
   ],
   "source": [
    "# 保存数据文件\n",
    "df = save_df(total, output_df_filename)\n",
    "with open(output_pickle_filename, 'wb') as file:\n",
    "    pickle.dump(total, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug-找几个gene_id，确定原始数据与合并后数据是否一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 统计\n",
    "gene_info = get_gene_info(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 打印统计信息\n",
    "print('\\n')\n",
    "temp_1 = gene_info.query(\"start==1 and end==1\")\n",
    "temp_2 = gene_info.query(\"start==1 and end!=1\")\n",
    "temp_3 = gene_info.query(\"start!=1 and end==1\")\n",
    "temp_4 = gene_info.query(\"start!=1 and end!=1\")\n",
    "print(\"单TSS且单TES, gene数量: {}, transcripts数量: {}\".format(temp_1.shape[0], temp_1[\"transcripts\"].sum()))\n",
    "print(\"单TSS且多TES, gene数量: {}, transcripts数量: {}\".format(temp_2.shape[0], temp_2[\"transcripts\"].sum()))\n",
    "print(\"多TSS且单TES, gene数量: {}, transcripts数量: {}\".format(temp_3.shape[0], temp_3[\"transcripts\"].sum()))\n",
    "print(\"多TSS且多TES, gene数量: {}, transcripts数量: {}\".format(temp_4.shape[0], temp_4[\"transcripts\"].sum()))\n",
    "\n",
    "print(\"[{}]All blocks finished.\".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
